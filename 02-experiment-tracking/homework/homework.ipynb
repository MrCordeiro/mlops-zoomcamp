{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "740766fb",
   "metadata": {},
   "source": [
    "# Experiment Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41062d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "PROJECT_DIR = Path().absolute().parent.parent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a50a44c6",
   "metadata": {},
   "source": [
    "## Download dataset\n",
    "\n",
    "We'll use [the same NYC taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page). We'll use \"**Green** Taxi Trip Records\".\n",
    "\n",
    "Download the data for January, February and March 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "328fc195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists.\n",
      "File already exists.\n",
      "File already exists.\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = PROJECT_DIR / \"data\"\n",
    "S3_URL = \"https://d37ci6vzurychx.cloudfront.net/trip-data/\"\n",
    "FILE_NAMES = [\n",
    "    \"green_tripdata_2022-01.parquet\",\n",
    "    \"green_tripdata_2022-02.parquet\",\n",
    "    \"green_tripdata_2022-03.parquet\",\n",
    "]\n",
    "\n",
    "\n",
    "def download_data(file_name: str) -> None:\n",
    "    file_path = DATA_DIR / file_name\n",
    "    url = S3_URL + file_name\n",
    "\n",
    "    if not file_path.is_file():\n",
    "        print(\"File does not exist, downloading from S3 bucket.\")\n",
    "        if not file_path.parent.exists():\n",
    "            file_path.parent.mkdir(parents=True)\n",
    "        subprocess.run([\"wget\", \"-O\", file_path, url])\n",
    "        print(f\"File downloaded successfully and saved at {file_path}\")\n",
    "    else:\n",
    "        print(\"File already exists.\")\n",
    "\n",
    "\n",
    "for file_name in FILE_NAMES:\n",
    "    download_data(file_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81f3e821",
   "metadata": {},
   "source": [
    "## Q2. Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f83087c",
   "metadata": {},
   "source": [
    "Run the script `preprocess_data.py` to preprocess the data and save the resulting files in the `data/processed` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6d4991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import click\n",
    "from preprocess_data import run_data_prep\n",
    "\n",
    "\n",
    "ctx = click.Context(run_data_prep)\n",
    "ctx.invoke( \n",
    "    run_data_prep,\n",
    "    raw_data_path=str(DATA_DIR),\n",
    "    dest_path=str(DATA_DIR / \"preprocessed\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f58223b4",
   "metadata": {},
   "source": [
    "So what's the size of the saved DictVectorizer file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6309a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of DictVectorizer: 150.05859375 KB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "BYTES_IN_KILOBYTES = 1024\n",
    "\n",
    "def get_file_size(file_path):\n",
    "    size_in_bytes = os.path.getsize(file_path)\n",
    "    size_in_kilobytes = size_in_bytes / BYTES_IN_KILOBYTES\n",
    "    return size_in_kilobytes\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Size of DictVectorizer:\",\n",
    "    get_file_size(DATA_DIR / \"preprocessed\" / \"dv.pkl\"),\n",
    "    \"KB\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a45e240",
   "metadata": {},
   "source": [
    "## Q3. Train a model with autolog\n",
    "\n",
    "Modify the  `train.py` script to enable **autologging** with MLflow, execute the script and then launch the MLflow UI to check that the experiment run was properly tracked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c010ba60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/12 16:32:46 INFO mlflow.tracking.fluent: Experiment with name 'hw2_local_experiment' does not exist. Creating a new experiment.\n",
      "2023/06/12 16:32:54 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/fernando/code/mlops-zoomcamp/.venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. RMSE: 2.45\n",
      "Run ID: 54476df742a54cdd80f1cfbf05b3bfc4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def load_pickle(filename: str | Path):\n",
    "    with open(filename, \"rb\") as f_in:\n",
    "        return pickle.load(f_in)\n",
    "\n",
    "\n",
    "# Mlflow setup\n",
    "mlflow.set_tracking_uri(str(PROJECT_DIR / \"mlruns\"))\n",
    "mlflow.set_experiment(\"hw2_local_experiment\")\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "data_path = DATA_DIR / \"preprocessed\"\n",
    "X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
    "X_val, y_val = load_pickle(os.path.join(data_path, \"val.pkl\"))\n",
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    rf = RandomForestRegressor(max_depth=10, random_state=0)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_val)\n",
    "\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "    print(f\"Training complete. RMSE: {rmse:.2f}\")\n",
    "    \n",
    "    run_id = mlflow.active_run().info.run_id\n",
    "    print(f\"Run ID: {run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67dc9306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "\tmin_weight_fraction_leaf: 0.0\n",
      "\tmax_depth: 10\n",
      "\tbootstrap: True\n",
      "\tmin_samples_leaf: 1\n",
      "\tn_jobs: None\n",
      "\tmin_samples_split: 2\n",
      "\tverbose: 0\n",
      "\twarm_start: False\n",
      "\trandom_state: 0\n",
      "\tn_estimators: 100\n",
      "\tmax_samples: None\n",
      "\tmax_leaf_nodes: None\n",
      "\tccp_alpha: 0.0\n",
      "\toob_score: False\n",
      "\tmax_features: 1.0\n",
      "\tmin_impurity_decrease: 0.0\n",
      "\tcriterion: squared_error\n",
      "Metrics:\n",
      "\ttraining_root_mean_squared_error: 1.9456616836464489\n",
      "\ttraining_score: 0.2905920668431764\n",
      "\ttraining_r2_score: 0.2905920668431764\n",
      "\ttraining_mean_absolute_error: 1.4846553814437824\n",
      "\tmean_squared_error_X_val: 2.453983836538874\n",
      "\ttraining_mean_squared_error: 3.785599387209934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the logged parameters and metrics\n",
    "run = mlflow.get_run(run_id)\n",
    "\n",
    "print(\"Parameters:\")\n",
    "[print(f\"\\t{key}: {value}\") for key, value in run.data.params.items()]\n",
    "\n",
    "print(\"Metrics:\")\n",
    "[print(f\"\\t{key}: {value}\") for key, value in run.data.metrics.items()]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eec36e61",
   "metadata": {},
   "source": [
    "## Q4. Tune model hyperparameters\n",
    "\n",
    "Now let's try to reduce the validation error by tuning the hyperparameters of the `RandomForestRegressor` using `optuna`.\n",
    "\n",
    "We have prepared the script `hpo.py` for this exercise.\n",
    "\n",
    "Make sure that the validation RMSE is logged to the tracking server for each run of the hyperparameter optimization (you will need to add a few lines of code to the `objective` function) and run the script without passing any parameters.\n",
    "\n",
    "Start the MLflow Server with:\n",
    "\n",
    "```bash\n",
    "mlflow server --backend-store-uri sqlite:///mlruns.db --default-artifact-root ./mlruns\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "781f2723",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-06 17:22:47,036] A new study created in memory with name: no-name-a9d4066b-6a4c-4107-b37e-f01352fea9e5\n",
      "[I 2023-06-06 17:22:47,639] Trial 0 finished with value: 2.451379690825458 and parameters: {'n_estimators': 25, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 0 with value: 2.451379690825458.\n",
      "[I 2023-06-06 17:22:47,766] Trial 1 finished with value: 2.4667366020368333 and parameters: {'n_estimators': 16, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 0 with value: 2.451379690825458.\n",
      "[I 2023-06-06 17:22:48,420] Trial 2 finished with value: 2.449827329704216 and parameters: {'n_estimators': 34, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 2 with value: 2.449827329704216.\n",
      "[I 2023-06-06 17:22:48,712] Trial 3 finished with value: 2.460983516558473 and parameters: {'n_estimators': 44, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 2 with value: 2.449827329704216.\n",
      "[I 2023-06-06 17:22:49,016] Trial 4 finished with value: 2.453877262701052 and parameters: {'n_estimators': 22, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 2 with value: 2.449827329704216.\n",
      "[I 2023-06-06 17:22:49,196] Trial 5 finished with value: 2.4720122094960733 and parameters: {'n_estimators': 35, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 2 with value: 2.449827329704216.\n",
      "[I 2023-06-06 17:22:49,733] Trial 6 finished with value: 2.4516421799356767 and parameters: {'n_estimators': 28, 'max_depth': 16, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 2 with value: 2.449827329704216.\n",
      "[I 2023-06-06 17:22:49,873] Trial 7 finished with value: 2.5374040268274087 and parameters: {'n_estimators': 34, 'max_depth': 1, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 2 with value: 2.449827329704216.\n",
      "[I 2023-06-06 17:22:50,185] Trial 8 finished with value: 2.455971238567075 and parameters: {'n_estimators': 12, 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 2 with value: 2.449827329704216.\n",
      "[I 2023-06-06 17:22:50,302] Trial 9 finished with value: 2.486106021576535 and parameters: {'n_estimators': 22, 'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 2 with value: 2.449827329704216.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import mlflow\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Set new experiment using sqlite as backend\n",
    "MLFLOW_TRACKING_URI = PROJECT_DIR / \"mlflow.db\"\n",
    "mlflow.set_tracking_uri(\"sqlite:///\" + MLFLOW_TRACKING_URI.as_posix())\n",
    "\n",
    "# Turn off autologging\n",
    "mlflow.sklearn.autolog(disable=True)\n",
    "\n",
    "\n",
    "mlflow.set_experiment(\"random-forest-hyperopt\")\n",
    "\n",
    "\n",
    "def load_pickle(filename):\n",
    "    with open(filename, \"rb\") as f_in:\n",
    "        return pickle.load(f_in)\n",
    "\n",
    "\n",
    "def run_optimization(data_path: str, num_trials: int):\n",
    "    X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
    "    X_val, y_val = load_pickle(os.path.join(data_path, \"val.pkl\"))\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 50, 1),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 1, 20, 1),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10, 1),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 4, 1),\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1,\n",
    "        }\n",
    "\n",
    "        rf = RandomForestRegressor(**params)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_val)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        return rmse\n",
    "\n",
    "    sampler = TPESampler(seed=42)\n",
    "    study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "    study.optimize(objective, n_trials=num_trials)\n",
    "\n",
    "\n",
    "data_path = str(DATA_DIR / \"preprocessed\")\n",
    "num_trials = 10\n",
    "run_optimization(data_path, num_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a87e2e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best run ID: fd7e32f30f6a434f8684857bc03d2ab9\n",
      "Best RMSE metrics: 2.45\n"
     ]
    }
   ],
   "source": [
    "experiment = mlflow.get_experiment_by_name(\"random-forest-hyperopt\")\n",
    "runs = mlflow.search_runs(experiment.experiment_id)\n",
    "\n",
    "best_run = runs.loc[runs[\"metrics.rmse\"].idxmin()]\n",
    "best_run_id = best_run.run_id\n",
    "\n",
    "print(f\"Best run ID: {best_run_id}\")\n",
    "print(f\"Best RMSE metrics: {best_run['metrics.rmse']:.2f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19d9057c",
   "metadata": {},
   "source": [
    "## Q5. Promote the best model to the model registry\n",
    "\n",
    "Update the script `register_model.py` so that it selects the model with the lowest RMSE on the test set and registers it to the model registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b9e3e08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/06 17:22:51 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: [Errno 13] Permission denied: '/home/fernando/code/mlops-zoomcamp/mlruns/2'\n",
      "2023/06/06 17:22:51 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: [Errno 13] Permission denied: '/home/fernando/code/mlops-zoomcamp/mlruns/2'\n",
      "2023/06/06 17:22:52 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: [Errno 13] Permission denied: '/home/fernando/code/mlops-zoomcamp/mlruns/2'\n",
      "2023/06/06 17:22:53 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: [Errno 13] Permission denied: '/home/fernando/code/mlops-zoomcamp/mlruns/2'\n",
      "2023/06/06 17:22:54 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: [Errno 13] Permission denied: '/home/fernando/code/mlops-zoomcamp/mlruns/2'\n",
      "Registered model 'random-forest-model' already exists. Creating a new version of this model...\n",
      "2023/06/06 17:22:54 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: random-forest-model, version 3\n",
      "Created version '3' of model 'random-forest-model'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1686068574139, current_stage='None', description=None, last_updated_timestamp=1686068574139, name='random-forest-model', run_id='307957faf8a043a6b041cf98c652d961', run_link=None, source='/home/fernando/code/mlops-zoomcamp/mlruns/2/307957faf8a043a6b041cf98c652d961/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=3>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import mlflow\n",
    "\n",
    "from mlflow.entities import ViewType\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "HPO_EXPERIMENT_NAME = \"random-forest-hyperopt\"\n",
    "EXPERIMENT_NAME = \"random-forest-best-models\"\n",
    "RF_PARAMS = [\n",
    "    \"max_depth\",\n",
    "    \"n_estimators\",\n",
    "    \"min_samples_split\",\n",
    "    \"min_samples_leaf\",\n",
    "    \"random_state\",\n",
    "    \"n_jobs\",\n",
    "]\n",
    "\n",
    "\n",
    "MLFLOW_TRACKING_URI = PROJECT_DIR / \"mlflow.db\"\n",
    "mlflow.set_tracking_uri(\"sqlite:///\" + MLFLOW_TRACKING_URI.as_posix())\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "\n",
    "def load_pickle(filename):\n",
    "    with open(filename, \"rb\") as f_in:\n",
    "        return pickle.load(f_in)\n",
    "\n",
    "\n",
    "def train_and_log_model(data_path, params):\n",
    "    X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
    "    X_val, y_val = load_pickle(os.path.join(data_path, \"val.pkl\"))\n",
    "    X_test, y_test = load_pickle(os.path.join(data_path, \"test.pkl\"))\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        for param in RF_PARAMS:\n",
    "            params[param] = int(params[param])\n",
    "\n",
    "        rf = RandomForestRegressor(**params)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate model on the validation and test sets\n",
    "        val_rmse = mean_squared_error(y_val, rf.predict(X_val), squared=False)\n",
    "        mlflow.log_metric(\"val_rmse\", val_rmse)\n",
    "        test_rmse = mean_squared_error(y_test, rf.predict(X_test), squared=False)\n",
    "        mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "\n",
    "def run_model_optimizer(data_path: Path, top_n: int = 5):\n",
    "\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # Retrieve the top_n model runs and log the models\n",
    "    experiment = client.get_experiment_by_name(HPO_EXPERIMENT_NAME)\n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=experiment.experiment_id,\n",
    "        run_view_type=ViewType.ACTIVE_ONLY,\n",
    "        max_results=top_n,\n",
    "        order_by=[\"metrics.rmse ASC\"],\n",
    "    )\n",
    "    for run in runs:\n",
    "        train_and_log_model(data_path=data_path, params=run.data.params)\n",
    "\n",
    "    # Select the model with the lowest test RMSE\n",
    "    experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    best_run = client.search_runs(\n",
    "        experiment_ids=experiment.experiment_id,\n",
    "        run_view_type=ViewType.ACTIVE_ONLY,\n",
    "        max_results=1,\n",
    "        order_by=[\"metrics.test_rmse ASC\"],\n",
    "    )[0]\n",
    "\n",
    "    return best_run\n",
    "\n",
    "\n",
    "best_run = run_model_optimizer(data_path=DATA_DIR / \"preprocessed\")\n",
    "mlflow.register_model(\n",
    "    f\"runs:/{best_run.info.run_id}/model\",\n",
    "    \"random-forest-model\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "251c793f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best run ID: b457d6ddac3741e9932fcd0dfd96ec5d\n",
      "Best test RMSE: 2.29\n"
     ]
    }
   ],
   "source": [
    "# Print the best run ID and the best test RMSE\n",
    "print(f\"Best run ID: {best_run.info.run_id}\")\n",
    "print(f\"Best test RMSE: {best_run.data.metrics['test_rmse']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
